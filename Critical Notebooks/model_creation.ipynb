{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "from datetime import datetime,date\n",
    "from pytz import timezone\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Flatten\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36mGetting Timezone ... Asia/Kolkata\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tizone = r'Asia/Kolkata'\n",
    "print(f'\\x1b[1;36mGetting Timezone ... {tizone}\\x1b[0m')\n",
    "ist = timezone(tizone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36mGetting Dates\u001b[0m\n",
      "\n",
      "\u001b[1;36mStart Date        \u001b[1;32m2018-Jan-01\u001b[0m\n",
      "\u001b[1;36mEnd Date          \u001b[1;32m2023-Oct-24\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'\\x1b[1;36mGetting Dates\\x1b[0m\\n')\n",
    "start_date = datetime(2018,1,1)\n",
    "end_date = datetime.now()\n",
    "start_timestamp = int(round(datetime.timestamp(start_date),0))\n",
    "end_timestamp = int(round(datetime.timestamp(end_date),0))\n",
    "print(f'\\x1b[1;36mStart Date        \\x1b[1;32m{start_date.strftime(\"%Y-%b-%d\")}\\x1b[0m')\n",
    "print(f'\\x1b[1;36mEnd Date          \\x1b[1;32m{end_date.strftime(\"%Y-%b-%d\")}\\x1b[0m\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36mStarting Yahoo Instance\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'\\x1b[1;36mStarting Yahoo Instance\\x1b[0m\\n')\n",
    "nifty_url = f'https://query1.finance.yahoo.com/v7/finance/download/%5ENSEI?period1={start_timestamp}&period2={end_timestamp}&interval=1d&events=history&includeAdjustedClose=true'\n",
    "nifty_bank_url = f'https://query1.finance.yahoo.com/v7/finance/download/%5ENSEBANK?period1={start_timestamp}&period2={end_timestamp}&interval=1d&events=history&includeAdjustedClose=true'\n",
    "nifty_fin_services_url = f'https://query1.finance.yahoo.com/v7/finance/download/NIFTY_FIN_SERVICE.NS?period1={start_timestamp}&period2={end_timestamp}&interval=1d&events=history&includeAdjustedClose=true'\n",
    "reliance_url = f'https://query1.finance.yahoo.com/v7/finance/download/RELIANCE.NS?period1={start_timestamp}&period2={end_timestamp}&interval=1d&events=history&includeAdjustedClose=true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32mNifty 50\u001b[0m\n",
      "\u001b[1;32mNifty Bank\u001b[0m\n",
      "\u001b[1;32mNifty Financial Services\u001b[0m\n",
      "\u001b[1;32mReliance\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_nifty50 = pd.read_csv(nifty_url)\n",
    "print(f'\\x1b[1;32mNifty 50\\x1b[0m')\n",
    "df_niftybank = pd.read_csv(nifty_bank_url)\n",
    "print(f'\\x1b[1;32mNifty Bank\\x1b[0m')\n",
    "df_niftyfin = pd.read_csv(nifty_fin_services_url)\n",
    "print(f'\\x1b[1;32mNifty Financial Services\\x1b[0m')\n",
    "df_reliance = pd.read_csv(reliance_url)\n",
    "print(f'\\x1b[1;32mReliance\\x1b[0m\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;36mCleaning the Data\u001b[0m\n",
      "\n",
      "\u001b[1;32mRemoved missing values\u001b[0m\n",
      "\u001b[1;32mRounded the data to 2 decimal place\u001b[0m\n",
      "\u001b[1;32mRemoved Extra Rows\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n\\x1b[1;36mCleaning the Data\\x1b[0m\\n')\n",
    "\n",
    "# Remove Missing Values\n",
    "\n",
    "df_nifty50.dropna(inplace=True)\n",
    "df_niftybank.dropna(inplace=True)\n",
    "df_niftyfin.dropna(inplace=True)\n",
    "df_reliance.dropna(inplace=True)\n",
    "\n",
    "print(f'\\x1b[1;32mRemoved missing values\\x1b[0m')\n",
    "\n",
    "# Round data to 2 decimal places\n",
    "\n",
    "df_nifty50 = df_nifty50.round(2)\n",
    "df_niftybank = df_niftybank.round(2)\n",
    "df_niftyfin = df_niftyfin.round(2)\n",
    "df_reliance = df_reliance.round(2)\n",
    "\n",
    "print(f'\\x1b[1;32mRounded the data to 2 decimal place\\x1b[0m')\n",
    "\n",
    "# Removing Extra Rows\n",
    "\n",
    "df_nifty50.drop(['Volume','Adj Close'],axis=1,inplace=True)\n",
    "df_niftybank.drop(['Volume','Adj Close'],axis=1,inplace=True)\n",
    "df_niftyfin.drop(['Volume','Adj Close'],axis=1,inplace=True)\n",
    "df_reliance.drop(['Volume','Adj Close'],axis=1,inplace=True)\n",
    "\n",
    "print(f'\\x1b[1;32mRemoved Extra Rows\\x1b[0m\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;36mScaling the Data\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n\\x1b[1;36mScaling the Data\\x1b[0m\\n')\n",
    "\n",
    "\n",
    "# function to perform Min-Max scaling with bias\n",
    "def min_max_scaling_with_bias(column, bias_min=None, bias_max=None):\n",
    "    # calculate the minimum and maximum values of the column\n",
    "    column_min = column.min()\n",
    "    column_max = column.max()\n",
    "\n",
    "    # add bias to the minimum and maximum values if specified\n",
    "    if bias_min is not None:\n",
    "        column_min -= bias_min\n",
    "    if bias_max is not None:\n",
    "        column_max += bias_max\n",
    "\n",
    "    # perform Min-Max scaling\n",
    "    column_scaled = (column - column_min) / (column_max - column_min)\n",
    "\n",
    "    return column_scaled, column_min, column_max\n",
    "\n",
    "\n",
    "\n",
    "# function to perform inverse transformation and return the original values\n",
    "def min_max_scaling_inverse(column_scaled, column_min, column_max, bias_min=None, bias_max=None):\n",
    "    # remove bias from the minimum and maximum values if specified\n",
    "    if bias_min is not None:\n",
    "        column_min += bias_min\n",
    "    if bias_max is not None:\n",
    "        column_max -= bias_max\n",
    "\n",
    "    # perform inverse transformation\n",
    "    column_unscaled = column_scaled * (column_max - column_min) + column_min\n",
    "\n",
    "    return column_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32mSelecting Column\u001b[0m\n",
      "\u001b[1;32mData Scaled Successfully\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'\\x1b[1;32mSelecting Column\\x1b[0m')\n",
    "col = 'Close'\n",
    "scaled_nifty50, min_nifty50_val, max_nifty50_val = min_max_scaling_with_bias(df_nifty50[col],bias_min=1000, bias_max=1000)\n",
    "scaled_niftybank, min_niftybank_val, max_niftybank_val = min_max_scaling_with_bias(df_niftybank[col],bias_min=1000, bias_max=1000)\n",
    "scaled_niftyfin, min_niftyfin_val, max_niftyfin_val = min_max_scaling_with_bias(df_niftyfin[col],bias_min=1000, bias_max=1000)\n",
    "scaled_reliance, min_reliance_val, max_reliance_val = min_max_scaling_with_bias(df_reliance[col],bias_min=1000, bias_max=1000)\n",
    "print(f'\\x1b[1;32mData Scaled Successfully\\x1b[0m\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;36mPreprocessing the Data\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32mNifty 50\u001b[0m: 100%|██████████| 1401/1401 [00:00<00:00, 9189.86it/s]\n",
      "\u001b[1;32mNifty Bank\u001b[0m: 100%|██████████| 1398/1398 [00:00<00:00, 4795.85it/s]\n",
      "\u001b[1;32mNifty Financial Services\u001b[0m: 100%|██████████| 1392/1392 [00:00<00:00, 7560.94it/s]\n",
      "\u001b[1;32mReliance\u001b[0m: 100%|██████████| 1405/1405 [00:00<00:00, 7783.22it/s]\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n\\x1b[1;36mPreprocessing the Data\\x1b[0m\\n')\n",
    "\n",
    "input_seq_len = 30\n",
    "output_seq_len = 1\n",
    "\n",
    "# Nifty 50\n",
    "\n",
    "X_nifty50 = []\n",
    "y_nifty50 = []\n",
    "\n",
    "for i in tqdm(range(len(scaled_nifty50) - input_seq_len - output_seq_len),desc='\\x1b[1;32mNifty 50\\x1b[0m'):\n",
    "    X_nifty50.append(scaled_nifty50[i:i+input_seq_len])\n",
    "    y_nifty50.append(scaled_nifty50[i+input_seq_len:i+input_seq_len+output_seq_len])\n",
    "\n",
    "\n",
    "X_nifty50 = np.array(X_nifty50)\n",
    "y_nifty50 = np.array(y_nifty50)\n",
    "\n",
    "# Nifty Bank\n",
    "\n",
    "X_niftybank = []\n",
    "y_niftybank = []\n",
    "\n",
    "for i in tqdm(range(len(scaled_niftybank) - input_seq_len - output_seq_len),desc='\\x1b[1;32mNifty Bank\\x1b[0m'):\n",
    "    X_niftybank.append(scaled_niftybank[i:i+input_seq_len])\n",
    "    y_niftybank.append(scaled_niftybank[i+input_seq_len:i+input_seq_len+output_seq_len])\n",
    "\n",
    "\n",
    "X_niftybank = np.array(X_niftybank)\n",
    "y_niftybank = np.array(y_niftybank)\n",
    "\n",
    "# Nifty Financial Services\n",
    "\n",
    "X_niftyfin = []\n",
    "y_niftyfin = []\n",
    "\n",
    "for i in tqdm(range(len(scaled_niftyfin) - input_seq_len - output_seq_len),desc='\\x1b[1;32mNifty Financial Services\\x1b[0m'):\n",
    "    X_niftyfin.append(scaled_niftyfin[i:i+input_seq_len])\n",
    "    y_niftyfin.append(scaled_niftyfin[i+input_seq_len:i+input_seq_len+output_seq_len])\n",
    "\n",
    "\n",
    "X_niftyfin = np.array(X_niftyfin)\n",
    "y_niftyfin = np.array(y_niftyfin)\n",
    "\n",
    "# Reliance\n",
    "\n",
    "X_reliance = []\n",
    "y_reliance = []\n",
    "\n",
    "for i in tqdm(range(len(scaled_reliance) - input_seq_len - output_seq_len),desc='\\x1b[1;32mReliance\\x1b[0m'):\n",
    "    X_reliance.append(scaled_reliance[i:i+input_seq_len])\n",
    "    y_reliance.append(scaled_reliance[i+input_seq_len:i+input_seq_len+output_seq_len])\n",
    "\n",
    "\n",
    "X_reliance = np.array(X_reliance)\n",
    "y_reliance = np.array(y_reliance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;36mSplitting the data appropriately\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n\\x1b[1;36mSplitting the data appropriately\\x1b[0m\\n')\n",
    "\n",
    "# Splitting Nifty 50 data\n",
    "X_nifty50_train, X_nifty50_test, y_nifty50_train, y_nifty50_test = train_test_split(\n",
    "    X_nifty50, y_nifty50, test_size=0.2, random_state=42)\n",
    "\n",
    "# Splitting Nifty Bank data\n",
    "X_niftybank_train, X_niftybank_test, y_niftybank_train, y_niftybank_test = train_test_split(\n",
    "    X_niftybank, y_niftybank, test_size=0.2, random_state=42)\n",
    "\n",
    "# Splitting Nifty Financial Services data\n",
    "X_niftyfin_train, X_niftyfin_test, y_niftyfin_train, y_niftyfin_test = train_test_split(\n",
    "    X_niftyfin, y_niftyfin, test_size=0.2, random_state=42)\n",
    "\n",
    "# Splitting Reliance data\n",
    "X_reliance_train, X_reliance_test, y_reliance_train, y_reliance_test = train_test_split(\n",
    "    X_reliance, y_reliance, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 30)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_nifty50_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;36mCreating Models\u001b[0m\n",
      "\n",
      "\u001b[1;32mFor Nifty 50\u001b[0m\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 28, 32)            128       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 14, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 14, 64)            24832     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 896)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               114816    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,905\n",
      "Trainable params: 139,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\u001b[1;32mFor Nifty Bank\u001b[0m\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_1 (Conv1D)           (None, 28, 32)            128       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 14, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 14, 64)            24832     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 896)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               114816    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,905\n",
      "Trainable params: 139,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\u001b[1;32mFor Nifty Financial Services\u001b[0m\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 28, 32)            128       \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 14, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 14, 64)            24832     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 896)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               114816    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,905\n",
      "Trainable params: 139,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\u001b[1;32mFor Reliance\u001b[0m\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (None, 28, 32)            128       \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 14, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 14, 64)            24832     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 896)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               114816    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,905\n",
      "Trainable params: 139,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n\\x1b[1;36mCreating Models\\x1b[0m\\n')\n",
    "\n",
    "# Clear any existing TensorFlow graph\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Nifty 50\n",
    "\n",
    "model_nifty50 = Sequential([\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(30, 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Adjust the number of output units for your task\n",
    "])\n",
    "print(f'\\x1b[1;32mFor Nifty 50\\x1b[0m')\n",
    "model_nifty50.summary()\n",
    "model_nifty50.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# Nifty Bank\n",
    "\n",
    "model_niftybank = Sequential([\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(30, 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Adjust the number of output units for your task\n",
    "])\n",
    "print(f'\\x1b[1;32mFor Nifty Bank\\x1b[0m')\n",
    "model_niftybank.summary()\n",
    "model_niftybank.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# Nifty Financial Services\n",
    "\n",
    "model_niftyfin = Sequential([\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(30, 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Adjust the number of output units for your task\n",
    "])\n",
    "print(f'\\x1b[1;32mFor Nifty Financial Services\\x1b[0m')\n",
    "model_niftyfin.summary()\n",
    "model_niftyfin.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# Reliance\n",
    "\n",
    "model_reliance = Sequential([\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(30, 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Adjust the number of output units for your task\n",
    "])\n",
    "print(f'\\x1b[1;32mFor Reliance\\x1b[0m')\n",
    "model_reliance.summary()\n",
    "model_reliance.compile(loss='mse', optimizer='adam')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 11ms/step - loss: 0.0250\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.0026\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.0019\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.0017\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.0015\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.0014\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.0014\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 1s 15ms/step - loss: 0.0011\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 1s 16ms/step - loss: 9.9809e-04\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 9.5614e-04\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 8.5250e-04\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 7.8747e-04\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 7.7725e-04\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 7.7119e-04\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 6.2059e-04\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 6.2293e-04\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 5.8425e-04\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 6.0061e-04\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 6.0153e-04\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 6.6404e-04\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 5.5169e-04\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 5.9287e-04\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 5.1461e-04\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 5.6355e-04\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 4.9429e-04\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 4.7582e-04\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 4.5829e-04\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 4.3860e-04\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 4.8432e-04\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 4.3313e-04\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.8659e-04\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.9671e-04\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.9059e-04\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 4.0299e-04\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.6231e-04\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.5472e-04\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 3.4858e-04\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 3.1337e-04\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.7440e-04\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.2662e-04\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 2.8159e-04\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 3.3044e-04\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 2.8190e-04\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.3961e-04\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.1938e-04\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.5474e-04\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.7603e-04\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 3.1027e-04\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.5177e-04\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.6868e-04\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.5761e-04\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.4357e-04\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 2.2513e-04\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 2.1038e-04\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.1245e-04\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 2.1726e-04\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.9866e-04\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 2.1590e-04\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.9926e-04\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 2.2212e-04\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 2.7651e-04\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.7642e-04\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.7308e-04\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.1021e-04\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.0135e-04\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.9400e-04\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.8034e-04\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 2.0807e-04\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.8440e-04\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.7564e-04\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 1.6642e-04\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.8465e-04\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.7281e-04\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.9704e-04\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.7652e-04\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.5539e-04\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.6653e-04\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.7039e-04\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.5024e-04\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.6612e-04\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.5043e-04\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.6168e-04\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.7881e-04\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.5281e-04\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 1.9756e-04\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.6778e-04\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.2490e-04\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.8673e-04\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.5608e-04\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.5101e-04\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.6000e-04\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.8186e-04\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.1815e-04\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.3450e-04\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.4552e-04\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.6087e-04\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.5058e-04\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 1.3797e-04\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.5471e-04\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.5607e-04\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 11ms/step - loss: 0.0219\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.0024\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.0016\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.0018\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.0016\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.0014\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.0012\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.0014\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.0014\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 9.8859e-04\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 8.0625e-04\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 7.9695e-04\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 8.4676e-04\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 7.6673e-04\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 7.3332e-04\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 6.9959e-04\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 7.2556e-04\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 6.4197e-04\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 5.9170e-04\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 5.7376e-04\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 5.6097e-04\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 5.1699e-04\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 5.7491e-04\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 5.4019e-04\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 5.0458e-04\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 5.8686e-04\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 4.8362e-04\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 4.6864e-04\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 5.5003e-04\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 4.3729e-04\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 4.4491e-04\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 4.6622e-04\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 4.7120e-04\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 3.9054e-04\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.7861e-04\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.8106e-04\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 3.6122e-04\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 3.4115e-04\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 5.2025e-04\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 4.2276e-04\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 3.0925e-04\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 3.2055e-04\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 2.9582e-04\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 2.8076e-04\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 2.5750e-04\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 2.8399e-04\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.5599e-04\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.9534e-04\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 2.9284e-04\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.2414e-04\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.1440e-04\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.1508e-04\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.9361e-04\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.1141e-04\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 2.4478e-04\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.2987e-04\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 1.9162e-04\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.2600e-04\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.8749e-04\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.9212e-04\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.7059e-04\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.6254e-04\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.7264e-04\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.6819e-04\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.7880e-04\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.6955e-04\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.6546e-04\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 1.5732e-04\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.7451e-04\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.6785e-04\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.4302e-04\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.4154e-04\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.3465e-04\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.5548e-04\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.5921e-04\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.5032e-04\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.4633e-04\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.3883e-04\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 1.4295e-04\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.7967e-04\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.8605e-04\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.4969e-04\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.3071e-04\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.2682e-04\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.3411e-04\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.3218e-04\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.2230e-04\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.2775e-04\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 1.3188e-04\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.2329e-04\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.3355e-04\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.4223e-04\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.2461e-04\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.1886e-04\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.3911e-04\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.3357e-04\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.5580e-04\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.2166e-04\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 1.4037e-04\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.2211e-04\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 12ms/step - loss: 0.0204\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.0023\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.0020\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.0016\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.0015\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.0015\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.0013\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.0011\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 14ms/step - loss: 0.0011\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 8.8363e-04\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 8.2718e-04\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 7.4936e-04\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 7.1110e-04\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 6.7806e-04\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 6.0459e-04\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 8.4363e-04\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 6.1507e-04\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 6.3047e-04\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 5.7955e-04\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 5.2964e-04\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 5.7258e-04\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 5.3972e-04\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 5.8753e-04\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 4.6235e-04\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 4.6887e-04\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 4.8624e-04\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 4.2760e-04\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 4.3064e-04\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 4.2687e-04\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 4.3214e-04\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.8467e-04\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 4.0091e-04\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.7197e-04\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 4.2882e-04\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.6282e-04\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 3.3046e-04\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.4217e-04\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 3.1329e-04\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.8894e-04\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.1292e-04\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 3.6222e-04\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.9876e-04\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.9027e-04\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 2.5283e-04\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 2.4376e-04\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.1542e-04\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 2.4669e-04\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.8326e-04\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.6343e-04\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.1546e-04\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 2.3800e-04\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.0773e-04\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 2.3969e-04\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 2.0798e-04\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.0053e-04\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.8526e-04\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 2.0033e-04\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.8464e-04\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.8480e-04\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.8228e-04\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.0171e-04\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.8163e-04\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.8669e-04\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 1.8421e-04\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.8414e-04\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.7959e-04\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.6581e-04\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.6871e-04\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.6182e-04\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.5296e-04\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.4502e-04\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.7040e-04\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.5528e-04\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.4381e-04\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.3665e-04\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.4816e-04\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.7230e-04\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.7227e-04\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.5656e-04\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.4612e-04\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.5437e-04\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.3763e-04\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.4412e-04\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.3876e-04\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.5351e-04\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.5116e-04\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.6305e-04\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.7538e-04\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 1.4307e-04\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.5189e-04\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.2598e-04\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.2972e-04\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.5436e-04\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 1.5055e-04\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.9346e-04\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.8479e-04\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 1.5110e-04\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.5368e-04\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.4968e-04\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.5758e-04\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 2s 12ms/step - loss: 0.0237\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 0.0025\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.0017\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.0016\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 0.0015\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.0014\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.0013\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.0011\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 8.6243e-04\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 9.0257e-04\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 7.8273e-04\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 7.1309e-04\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 0.0011\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 6.2756e-04\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 5.8311e-04\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 6.3925e-04\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 6.2222e-04\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 5.3015e-04\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 4.7611e-04\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 5.7270e-04\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 4.9395e-04\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 4.5387e-04\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 4.1264e-04\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 4.2108e-04\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 4.1347e-04\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 4.1771e-04\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.7317e-04\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 4.2763e-04\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 3.5132e-04\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 3.5156e-04\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.7881e-04\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.3903e-04\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.6604e-04\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.6318e-04\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 3.0983e-04\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 2.8471e-04\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 2.6239e-04\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.7170e-04\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 2.9389e-04\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 2.3640e-04\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.4177e-04\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 2.2702e-04\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.2235e-04\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 2.2237e-04\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.9728e-04\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.6967e-04\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.3094e-04\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.9235e-04\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.8683e-04\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.0214e-04\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 1.6932e-04\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.7905e-04\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.8978e-04\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 2.4422e-04\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.8879e-04\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.5381e-04\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.5967e-04\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 1.6075e-04\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.7898e-04\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.8468e-04\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.6039e-04\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.5676e-04\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.5229e-04\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.6046e-04\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 1.6328e-04\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.5113e-04\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.4224e-04\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.5247e-04\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.3337e-04\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.6651e-04\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.8876e-04\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 1.3433e-04\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.3152e-04\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.4114e-04\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.5538e-04\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.4834e-04\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.2793e-04\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.4033e-04\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 14ms/step - loss: 1.5861e-04\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.6154e-04\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.4567e-04\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.3904e-04\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.6493e-04\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 2.1168e-04\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.5107e-04\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 1.4381e-04\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.6167e-04\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.7715e-04\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.9003e-04\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.2895e-04\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.8019e-04\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.3748e-04\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.4026e-04\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.5235e-04\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.3487e-04\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 1.3505e-04\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 1.2920e-04\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.3848e-04\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 1.4676e-04\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 1.4497e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17d994eebb0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'\\n\\x1b[1;36mTraining Model\\x1b[0m\\n')\n",
    "\n",
    "model_nifty50.fit(X_nifty50_train, y_nifty50_train, epochs=100)\n",
    "model_niftybank.fit(X_nifty50_train, y_nifty50_train, epochs=100)\n",
    "model_niftyfin.fit(X_nifty50_train, y_nifty50_train, epochs=100)\n",
    "model_reliance.fit(X_nifty50_train, y_nifty50_train, epochs=100)\n",
    "\n",
    "print(f'\\n\\x1b[1;32mModel Trained Successfully\\x1b[0m\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 6ms/step\n",
      "9/9 [==============================] - 0s 6ms/step\n",
      "9/9 [==============================] - 0s 9ms/step\n",
      "9/9 [==============================] - 0s 8ms/step\n",
      "\n",
      "\n",
      "\u001b[1;36mMean Squared Error (Nifty 50): \u001b[1;32m0.00019965604503444185\u001b[0m\n",
      "\u001b[1;36mMean Squared Error (Nifty Bank): \u001b[1;32m0.0002941995079629641\u001b[0m\n",
      "\u001b[1;36mMean Squared Error (Nifty Financial Services): \u001b[1;32m0.0005394952931613597\u001b[0m\n",
      "\u001b[1;36mMean Squared Error (Reliance): \u001b[1;32m0.00013078222700308204\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test dataset\n",
    "y_pred_nifty50 = model_nifty50.predict(X_nifty50_test)\n",
    "y_pred_niftybank = model_niftybank.predict(X_niftybank_test)\n",
    "y_pred_niftyfin = model_niftyfin.predict(X_niftyfin_test)\n",
    "y_pred_reliance = model_reliance.predict(X_reliance_test)\n",
    "\n",
    "# Calculate the MSE\n",
    "mse_nifty50 = mean_squared_error(y_nifty50_test, y_pred_nifty50)\n",
    "mse_niftybank = mean_squared_error(y_niftybank_test, y_pred_niftybank)\n",
    "mse_niftyfin = mean_squared_error(y_niftyfin_test, y_pred_niftyfin)\n",
    "mse_reliance = mean_squared_error(y_reliance_test, y_pred_reliance)\n",
    "\n",
    "# Print the MSE\n",
    "print(f'\\n\\n\\x1b[1;36mMean Squared Error (Nifty 50): \\x1b[1;32m{mse_nifty50}\\x1b[0m')\n",
    "print(f'\\x1b[1;36mMean Squared Error (Nifty Bank): \\x1b[1;32m{mse_niftybank}\\x1b[0m')\n",
    "print(f'\\x1b[1;36mMean Squared Error (Nifty Financial Services): \\x1b[1;32m{mse_niftyfin}\\x1b[0m')\n",
    "print(f'\\x1b[1;36mMean Squared Error (Reliance): \\x1b[1;32m{mse_reliance}\\x1b[0m\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;36mSaving Models\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n\\x1b[1;36mSaving Models\\x1b[0m\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_directory = \"../src\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if \"models\" directory exists in \"src\"; if not, create it\n",
    "models_directory = os.path.join(src_directory, \"models\")\n",
    "if not os.path.exists(models_directory):\n",
    "    os.mkdir(models_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your models in the \"models\" directory\n",
    "model_nifty50.save(os.path.join(models_directory, \"model_nifty50.h5\"))\n",
    "model_niftybank.save(os.path.join(models_directory, \"model_niftybank.h5\"))\n",
    "model_niftyfin.save(os.path.join(models_directory, \"model_niftyfin.h5\"))\n",
    "model_reliance.save(os.path.join(models_directory, \"model_reliance.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;32mModels Saved Successfully\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n\\x1b[1;32mModels Saved Successfully\\x1b[0m\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required reverse scaling format\n",
    "\n",
    "# min_max_scaling_inverse(scaled_niftybank,min_niftybank_val-1000,max_niftybank_val+1000,bias_min=1000,bias_max=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
